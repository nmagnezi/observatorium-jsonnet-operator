apiVersion: v1
kind: Template
metadata:
  name: jaeger
objects:
- apiVersion: v1
  kind: Service
  metadata:
    labels:
      app.kubernetes.io/name: jaeger-all-in-one
    name: jaeger-admin
    namespace: ${NAMESPACE}
  spec:
    ports:
    - name: admin-http
      port: 14269
      targetPort: 14269
    selector:
      app.kubernetes.io/name: jaeger-all-in-one
- apiVersion: v1
  kind: Service
  metadata:
    labels:
      app.kubernetes.io/name: jaeger-agent
    name: jaeger-agent-discovery
    namespace: ${NAMESPACE}
  spec:
    ports:
    - name: metrics
      port: 14271
      targetPort: 14271
    selector:
      app.kubernetes.io/tracing: jaeger-agent
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    labels:
      app.kubernetes.io/name: jaeger-all-in-one
    name: jaeger-all-in-one
    namespace: ${NAMESPACE}
  spec:
    replicas: ${{REPLICAS}}
    selector:
      matchLabels:
        app.kubernetes.io/name: jaeger-all-in-one
    strategy:
      rollingUpdate:
        maxSurge: 0
        maxUnavailable: 1
    template:
      metadata:
        labels:
          app.kubernetes.io/name: jaeger-all-in-one
      spec:
        containers:
        - args:
          - --badger.directory-key=/var/jaeger/store/keys
          - --badger.directory-value=/var/jaeger/store/values
          - --badger.ephemeral=false
          - --collector.queue-size=4000
          env:
          - name: SPAN_STORAGE_TYPE
            value: badger
          image: ${IMAGE}:${IMAGE_TAG}
          livenessProbe:
            failureThreshold: 4
            httpGet:
              path: /
              port: 14269
              scheme: HTTP
            periodSeconds: 30
          name: jaeger-all-in-one
          ports:
          - containerPort: 14250
            name: grpc
          - containerPort: 14269
            name: admin-http
          - containerPort: 16686
            name: query
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: 14269
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 30
          resources:
            limits:
              cpu: "4"
              memory: 4Gi
            requests:
              cpu: "1"
              memory: 1Gi
          volumeMounts:
          - mountPath: /var/jaeger/store
            name: jaeger-store-data
            readOnly: false
        - args:
          - -provider=openshift
          - -https-address=:16687
          - -http-address=
          - -email-domain=*
          - -upstream=http://localhost:16686
          - -openshift-service-account=prometheus-telemeter
          - '-openshift-sar={"resource": "namespaces", "verb": "get", "name": "${NAMESPACE}",
            "namespace": "${NAMESPACE}"}'
          - '-openshift-delegate-urls={"/": {"resource": "namespaces", "verb": "get",
            "name": "${NAMESPACE}", "namespace": "${NAMESPACE}"}}'
          - -tls-cert=/etc/tls/private/tls.crt
          - -tls-key=/etc/tls/private/tls.key
          - -client-secret-file=/var/run/secrets/kubernetes.io/serviceaccount/token
          - -cookie-secret-file=/etc/proxy/secrets/session_secret
          - -openshift-ca=/etc/pki/tls/cert.pem
          - -openshift-ca=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          image: ${PROXY_IMAGE}:${PROXY_IMAGE_TAG}
          name: proxy
          ports:
          - containerPort: 16687
            name: https
          resources:
            limits:
              cpu: ${JAEGER_PROXY_CPU_LIMITS}
              memory: ${JAEGER_PROXY_MEMORY_LIMITS}
            requests:
              cpu: ${JAEGER_PROXY_CPU_REQUEST}
              memory: ${JAEGER_PROXY_MEMORY_REQUEST}
          volumeMounts:
          - mountPath: /etc/tls/private
            name: secret-jaeger-query-tls
            readOnly: false
          - mountPath: /etc/proxy/secrets
            name: secret-jaeger-proxy
            readOnly: false
        serviceAccount: prometheus-telemeter
        serviceAccountName: prometheus-telemeter
        volumes:
        - name: jaeger-store-data
          persistentVolumeClaim:
            claimName: jaeger-store-data
        - name: secret-jaeger-query-tls
          secret:
            secretName: jaeger-query-tls
        - name: secret-jaeger-proxy
          secret:
            secretName: jaeger-proxy
- apiVersion: v1
  kind: Service
  metadata:
    labels:
      app.kubernetes.io/name: jaeger-all-in-one
    name: jaeger-collector-headless
    namespace: ${NAMESPACE}
  spec:
    clusterIP: None
    ports:
    - name: grpc
      port: 14250
      targetPort: 14250
    selector:
      app.kubernetes.io/name: jaeger-all-in-one
- apiVersion: monitoring.coreos.com/v1
  kind: PrometheusRule
  metadata:
    labels:
      prometheus: app-sre
      role: alert-rules
    name: observatorium-jaeger
  spec:
    groups:
    - name: jaeger_alerts
      rules:
      - alert: JaegerHTTPServerErrs
        annotations:
          message: |
            {{ $labels.job }} {{ $labels.instance }} is experiencing {{ printf "%.2f" $value }}% HTTP errors.
        expr: 100 * sum(rate(jaeger_agent_http_server_errors_total[1m])) by (instance,
          job, namespace) / sum(rate(jaeger_agent_http_server_total[1m])) by (instance,
          job, namespace)> 1
        for: 15m
        labels:
          severity: warning
      - alert: JaegerRPCRequestsErrors
        annotations:
          message: |
            {{ $labels.job }} {{ $labels.instance }} is experiencing {{ printf "%.2f" $value }}% RPC HTTP errors.
        expr: 100 * sum(rate(jaeger_client_jaeger_rpc_http_requests{status_code=~"4xx|5xx"}[1m]))
          by (instance, job, namespace) / sum(rate(jaeger_client_jaeger_rpc_http_requests[1m]))
          by (instance, job, namespace)> 1
        for: 15m
        labels:
          severity: warning
      - alert: JaegerClientSpansDropped
        annotations:
          message: |
            service {{ $labels.job }} {{ $labels.instance }} is dropping {{ printf "%.2f" $value }}% spans.
        expr: 100 * sum(rate(jaeger_reporter_spans{result=~"dropped|err"}[1m])) by
          (instance, job, namespace) / sum(rate(jaeger_reporter_spans[1m])) by (instance,
          job, namespace)> 1
        for: 15m
        labels:
          severity: warning
      - alert: JaegerAgentSpansDropped
        annotations:
          message: |
            agent {{ $labels.job }} {{ $labels.instance }} is dropping {{ printf "%.2f" $value }}% spans.
        expr: 100 * sum(rate(jaeger_agent_reporter_batches_failures_total[1m])) by
          (instance, job, namespace) / sum(rate(jaeger_agent_reporter_batches_submitted_total[1m]))
          by (instance, job, namespace)> 1
        for: 15m
        labels:
          severity: warning
      - alert: JaegerCollectorDroppingSpans
        annotations:
          message: |
            collector {{ $labels.job }} {{ $labels.instance }} is dropping {{ printf "%.2f" $value }}% spans.
        expr: 100 * sum(rate(jaeger_collector_spans_dropped_total[1m])) by (instance,
          job, namespace) / sum(rate(jaeger_collector_spans_received_total[1m])) by
          (instance, job, namespace)> 1
        for: 15m
        labels:
          severity: warning
      - alert: JaegerSamplingUpdateFailing
        annotations:
          message: |
            {{ $labels.job }} {{ $labels.instance }} is failing {{ printf "%.2f" $value }}% in updating sampling policies.
        expr: 100 * sum(rate(jaeger_sampler_queries{result="err"}[1m])) by (instance,
          job, namespace) / sum(rate(jaeger_sampler_queries[1m])) by (instance, job,
          namespace)> 1
        for: 15m
        labels:
          severity: warning
      - alert: JaegerThrottlingUpdateFailing
        annotations:
          message: |
            {{ $labels.job }} {{ $labels.instance }} is failing {{ printf "%.2f" $value }}% in updating throttling policies.
        expr: 100 * sum(rate(jaeger_throttler_updates{result="err"}[1m])) by (instance,
          job, namespace) / sum(rate(jaeger_throttler_updates[1m])) by (instance,
          job, namespace)> 1
        for: 15m
        labels:
          severity: warning
      - alert: JaegerQueryReqsFailing
        annotations:
          message: |
            {{ $labels.job }} {{ $labels.instance }} is seeing {{ printf "%.2f" $value }}% query errors on {{ $labels.operation }}.
        expr: 100 * sum(rate(jaeger_query_requests_total{result="err"}[1m])) by (instance,
          job, namespace) / sum(rate(jaeger_query_requests_total[1m])) by (instance,
          job, namespace)> 1
        for: 15m
        labels:
          severity: warning
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      service.alpha.openshift.io/serving-cert-secret-name: jaeger-query-tls
    labels:
      app.kubernetes.io/name: jaeger-all-in-one
    name: jaeger-query
    namespace: ${NAMESPACE}
  spec:
    ports:
    - name: query
      port: 16686
      targetPort: 16686
    - name: https
      port: 16687
      targetPort: 16687
    selector:
      app.kubernetes.io/name: jaeger-all-in-one
- apiVersion: v1
  kind: PersistentVolumeClaim
  metadata:
    labels:
      app.kubernetes.io/name: jaeger-all-in-one
    name: jaeger-store-data
    namespace: ${NAMESPACE}
  spec:
    accessModes:
    - ReadWriteOnce
    resources:
      requests:
        storage: 50Gi
    storageClassName: gp2-encrypted
parameters:
- name: NAMESPACE
  value: telemeter
- name: IMAGE
  value: jaegertracing/all-in-one
- name: IMAGE_TAG
  value: 1.14.0
- name: REPLICAS
  value: "1"
- name: PROXY_IMAGE
  value: openshift/oauth-proxy
- name: PROXY_IMAGE_TAG
  value: v1.1.0
- name: JAEGER_PROXY_CPU_REQUEST
  value: 100m
- name: JAEGER_PROXY_MEMORY_REQUEST
  value: 100Mi
- name: JAEGER_PROXY_CPU_LIMITS
  value: 200m
- name: JAEGER_PROXY_MEMORY_LIMITS
  value: 200Mi
